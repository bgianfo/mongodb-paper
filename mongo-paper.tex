% THIS IS SIGPROC-SP.TEX - VERSION 3.1
% WORKS WITH V3.2SP OF ACM_PROC_ARTICLE-SP.CLS
% APRIL 2009
%
% It is an example file showing how to use the 'acm_proc_article-sp.cls' V3.2SP
% LaTeX2e document class file for Conference Proceedings submissions.
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V3.2SP) *DOES NOT* produce:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) Page numbering
% ---------------------------------------------------------------------------------------------------------------
% It is an example which *does* use the .bib file (from which the .bbl file
% is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission,
% you need to 'insert'  your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% Questions regarding SIGS should be sent to
% Adrienne Griscti ---> griscti@acm.org
%
% Questions/suggestions regarding the guidelines, .tex and .cls files, etc. to
% Gerald Murray ---> murray@hq.acm.org
%
% For tracking purposes - this is V3.1SP - APRIL 2009

\documentclass{dependencies/acm_proc_article-sp}

\usepackage{url}
\usepackage{color}
\usepackage{verbatim}
\usepackage{listings}
\lstset{
  language=C++,             % choose the language of the code
  basicstyle=\small,       % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  numberstyle=\footnotesize,      % the size of the fonts that are used for the line-numbers
  stepnumber=0,                   % the step between two line-numbers. If it is 1 each line will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code
  backgroundcolor=\color{white},  % choose the background color. You must add \usepackage{color}
  showspaces=false,               % show spaces adding particular underscores
  showstringspaces=false,         % underline spaces within strings
  showtabs=false,                 % show tabs within strings adding particular underscores
  %frame=single,                   % adds a frame around the code
  tabsize=2,              % sets default tabsize to 2 spaces
  captionpos=t,                   % sets the caption-position to bottom
  breaklines=false,        % sets automatic line breaking
  breakatwhitespace=false,    % sets if automatic breaks should only happen at whitespace
  escapeinside={\%}{)}          % if you want to add a comment within your code
}


\begin{document}

\title{ Analysis of MongoDB and Revised Proposal for Extensions }
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Brian Gianforcaro \\
       \affaddr{RIT}\\
       \email{bjg1955@rit.edu}
% 2nd. author
\alignauthor
Joseph Schrama \\
       \affaddr{RIT}\\
       \email{jfs2776@rit.edu}
% 3rd. author
\alignauthor
Nicholas Williams \\
       \affaddr{RIT}\\
       \email{nxw6572@rit.edu}
}
\maketitle
\begin{abstract}
This paper provides a brief overview of the MongoDB NoSQL database system.
We overview what we have discovered about how MongoDB works and describe in detail
a set of improvements to the database internals.
Our database system's implementation group then describes our proposed
extensions to MongoDB and our reasons for attempting them. A small
section of where exactly in the MongoDB code these extensions will be executed
is also provided under each individual proposal.
%the formatting guidelines for ACM SIG Proceedings.
%It complements the document \textit{Author's Guide to Preparing
%ACM SIG Proceedings Using \LaTeX$2_\epsilon$\ and Bib\TeX}. This
%source file has been written with the intention of being
%compiled under \LaTeX$2_\epsilon$\ and BibTeX.
%
%The developers have tried to include every imaginable sort
%of ``bells and whistles", such as a subtitle, footnotes on
%title, subtitle and authors, as well as in the text, and
%every optional component (e.g. Acknowledgments, Additional
%Authors, Appendices), not to mention examples of
%equations, theorems, tables and figures.
%
%To make best use of this sample document, run it through \LaTeX\
%and BibTeX, and compare this source code with the printed
%output produced by the dvi file.
\end{abstract}
u
%% A category with the (minimum) three required fields
\category{H.4}{Information Systems Applications}{Miscellaneous}
%%%A category including the fourth, optional field follows...
%
%\terms{Theory}

\keywords{ MongoDB, NoSQL, RIT, Database System Implementation, XPath, GeoSpatial Search, Building Index's in Parallel} % NOT required for Proceedings
%
%\footnotetext[1]{NoSQL databases, also known as structured storage are known for not requiring a fixed table schema and often avoid join operations. The thing that
% links them together is there use of alternate query languages from SQL.}

\section{Introduction}
Our group has chosen to work on MongoDB for our Database Systems
Implementation Project. MongoDB is a document oriented so-called NoSQL
database system. MongoDB databases have no schemata and strive to give the user
the fastest performance possible. Much of this is done through clustering/sharding
and a focus on concurrent algorithms. MongoDB has a variety of very unique
features which set it apart from other NoSQL or document oriented databases.
Instead of a traditional SQL syntax for interacting with the database, MongoDB uses
a new format known as BSON (Binary JavaScript Object Notation) which is very similar
to JSON ( JavaScript Object Notation ).
\begin{lstlisting}

{ "title":"Blog Post", "id":25, ... }
\end{lstlisting}
The database kernel and the tools built for interacting with MongoDB are written in
C++. The kernel and tools heavily utilize object oriented design patterns.
However, the database embeds the Mozilla SpiderMonkey JavaScript engine.
Using this engine JavaScript can be written, stored and executed on the database server; these
operations are similar to stored procedures. MongoDB also has a specification for storing
large files under MongoDB, known as GridFS. GridFS is a standard for breaking up these larger
files and storing them efficiently, a user can then query ranges of the file. For example if the
database is storing a large MP3 file, the user can seek to the middle of it and the database can
efficiently seek to the relevant section.

MongoDB is rich with new and exciting features and is a completely open source project.
The database has an active developers mailing list as well as an excellent issue tracker,
wiki for documentation and IRC channel for help. With all of these resources and
the many features requested on the issue tracker, our group felt that MongoDB would be a great
project to work on this quarter. The database has also been gaining a lot of traction in the
database world. MongoDB will more than likely prove to be a very useful product
to have working knowledge of in the future.

\section{Database Internals}
\subsection{Relations And Indexes}
MongoDB stores and represents relations as BSON documents\cite{1}.
BSON is a data serialization format which stores objects as a set of key-value pairs known as a document.
BSON documents can contain several different types of data, including integers, strings, arrays, and other documents\cite{2}.
In MongoDB, documents are contained in sets known as collections, which are analogous to tables in a relational database\cite{3}.
BSON documents are similar to rows in a relational table.
As MongoDB databases do not have schemata, their relations have no explicitly defined domains.
A collection's domain is defined by how it is treated.
For example, a field can be added by simply adding a new document with said field ( a newly added document does not need to have all of the fields of the other documents in the collection ).
The user does not specify which fields a collection will include before documents are inserted\cite{4}.
The C++ class mongo::BSONObj provides an abstraction of BSON object\cite{5}.
MongoDB indexes work in a similar manner to those of most RDBMS's.
MongoDB's indexes are B-Tree indexes (as opposed to B+Tree or B*Tree indexes).
Indexes can be created on one or more fields, and they can built as either ascending or descending on a particular field.
Each standard collection has a default index built on the \_id field.  Indexes can be built on fields of documents which are embedded as fields in other documents\cite{6}.
\subsection{Inserting Records Into The Database}
When data is inserted into MongoDB, that data will always be in document-form.
Documents are data structures analogous to JSON (JavaScript Object Notation), Python dictionaries, and Ruby hashes, to take just a few examples.
The particular data structure that MongoDB utilizes is called BSON.
BSON is a binary-encoded serialization of JSON-like documents, and is designed to be lightweight, traversable, and efficient.
BSON is faster to scan for specific fields than JSON.
BSON, like JSON, supports the embedding of objects and arrays within other objects and arrays.
BSON maps readily to and from JSON and also to various data structures (such as 32-bit integer, 64-bit integer, double, string, boolean, etc.) in many programming languages.
BSON also contains extensions that allow representation of data types that are not part of the JSON specification.
For example, BSON has a Date type and a BinData (Binary Data) type.

The process for inserting records into the database is as follows:
\begin{itemize}
  \item Create the document
  \begin{itemize}
    \item d = {'author':'John Doe', 'date':new Date() }
  \end{itemize}

  \item Insert the document
  \begin{itemize}
    \item db.collection.insert(d)
  \end{itemize}
\end{itemize}

\subsection{Key Values And Insertion Into Indexes}
By default, a command which builds an index acquires a lock on the entire database,
preventing all other operations. The index can be built in the background,
but with increased overhead.
A collection can only have one index built at a particular time\cite{7}.
\subsection{Page Fetching}
MongoDB takes an interesting strategy towards data storage for the database.
The database files are completely memory mapped by the kernel, this allows huge chunks and
even the entire database B-tree structure to be kept in memory.
It can then be read back out without needing to fetch data from the disk\cite{16}.
There is no need to have a cache to store the data being read, a buffer is managed
by the Operating System's Virtual Memory Manager. This allows MongoDB to focus on the data itself
and not on efficiently fetching pages and micromanaging disk locations. This strategy does come with
at a price. Because of how the files are memory mapped, the logical file size limit for any database
on a 32-bit system is just above 2 Gigabytes of data. This limit only exists on 32-bit systems, the
logical limit for 64-bit systems is significantly larger. The efficiency of the
Virtual Memory Manager on each operating system will vary and will determine the write performance
of the database it self.
\subsection{Query Processing And Optimizations}
One of MongoDB's best capabilities is its support for dynamic (ad hoc) queries, allowing it to find data without any special indexing; users can find data using any criteria.
As mentioned in previous sections, MongoDB stores data as BSON documents, so queries are expressed as BSON documents that indicate a query pattern.
For example, the query db.professors.find({'last\_name':'Raj'}) would return all of the entries in the 'professors' collection where the 'last\_name' attribute is 'Raj'.
Query patterns may also contain:
\begin{itemize}
\item Multiple criteria
 \begin{itemize}
  \item var col = db.collection
  \item col.find(\{'attr1':'val', 'attr2':'val', ...\})
 \end{itemize}
\item Modifiers
  \begin{itemize}
   \item var col = db.collection
   \item col.find(\{'attr':\{\$gte:1, \$lt:10, \$in [range], ...\})
  \end{itemize}
\item Projections where boolean\_int represents whether the projection returns only the 'attr' specified\cite{12} or all attributes except the one specified\cite{11}
  \begin{itemize}
    \item var col = db.collection
    \item col.find(\{\}, \{'attr' : boolean\_int\})
  \end{itemize}
\item Sorting results where the boolean\_int indicates whether the results are sorted in ascending order\cite{12} or in descending order\cite{11} based on 'attr'
  \begin{itemize}
    \item var col = db.collection
    \item col.find(\{\}).sort(\{'attr' : boolean\_int\})
  \end{itemize}
\item Skipping results, the following skips the first 10 results of the query
  \begin{itemize}
    \item var col = db.collection
    \item col.find(\{\}).skip(10)
  \end{itemize}
\item Limiting results only returns the first 10 results of the query
  \begin{itemize}
    \item var col = db.collection
    \item col.find(\{\}).limit(10)
  \end{itemize}
\end{itemize}

For a more exhaustive list of modifiers and result manipulators, see links\cite{11} and\cite{12} listed in 'References'.

The MongoDB query optimizer generates query plans for each query submitted by a client.
These plans are executed to return results.
Thus, MongoDB supports ad hoc queries much like MySQL for example.
Unlike traditional approaches to query optimization, the Mongo query optimizer is not cost based -- it does not model the cost of various queries.
Instead, the optimizer simply tries different query plans and learn which ones work well.
Of course, when the system tries a really bad plan, it may take an extremely long time to run.
To solve this, when testing new plans, MongoDB executes multiple query plans in parallel.
As soon as one finishes, it terminates the other executions, and the system has learned which plan is good.
This works particularly well given the system is non-relational, which makes the space of possible query plans much smaller (as there are no joins).
For some instances, a plan which has worked well in the past can work poorly.
For example if the data in the database has changed, or if the parameter values to the query are different.
In this case, if the query seems to be taking longer than usual, the database will once again run the query in parallel to try different plans.
This approach adds a little overhead, but has the advantage of being much better at worst-case performance\cite{13}.
\section{Proposed Extensions}
\subsection{Building Indexes In Parallel}
One extension we plan on adding is multi-threaded index creation.
Different threads can be tasked to build different sub-trees which will eventually be combined.
We will likely need to modify the $BtreeBuilder::addKey()$ member function, which starts at line 1238 of db/btree.cpp.  We will certainly need to modify the $fastBuildIndex()$ function which starts on line 1083 of db/pdfile.cpp.  This function deals with foreground index creation and uses a bottom-up approach which is not identical to that used by the background index creation process\cite{17}.  Our enhancements will be limited to the foreground index creation process.  The bottom-up approach sorts the keys and calculates the number of keys (see lines 1097 through 1187 of db/pdfile.cpp).  This will greatly facilitate the appropriation of key subsets to the threads. 

Multi-threaded index creation is important if the foreground indexing operation locks the entire database.  The background indexing operation is not much better, as it does not allow for further operations to be begun from the invoking shell session and it is slower than the foreground process\cite{17}.  It is always important to take advantage of multiprocessing.
Furthermore, JIRA ticket SERVER-676 requests this feature\cite{8}.

\subsection{XPath Like Queries Of Documents}
XPath is the result of an effort to provide a common syntax and semantics for functionality shared between XSL Transformations (XSLT) and XPointer.
The primary purpose of XPath is to address parts of an XML document\cite{10}.
In support of this primary purpose, it also provides basic facilities for manipulation of strings, numbers and booleans.
XPath uses a compact, non-XML syntax to facilitate use of XPath within URIs and XML attribute values.
XPath operates on the abstract, logical structure of an XML document, rather than its surface syntax.
XPath gets its name from its use of a path notation as in URLs for navigating through the hierarchical structure of an XML document.

The main reasoning behind adding XPath-like queries to MongoDB is the needed ability to quickly and easily find specific sub-trees in a BSON document.
For example, if a user wishes to find entries with a specific value for a known tree structure in a collection, this can be easily accomplished using the following XPath query:
The feature was requested under the JIRA ISSUE SERVER-736\cite{15}.

\begin{lstlisting}

/tree_root_node/subnode1[subnode2=value]
\end{lstlisting}
Natively, one would execute a BSON document query in the following form to retrieve the same data:

\begin{lstlisting}

{treeRootNode:{subnode1:{subnode2:val}}}
\end{lstlisting}
One huge benefit to XPath queries, however, is the fact that you need not know the entire tree structure to retrieve from sub-trees, due to the inclusion of the wild card operator.
Therefore, if the user only knows the specific sub-tree they are searching for they can execute an XPath query such as the following:


\begin{center}
\begin{lstlisting}

//*[subnode2=value]
\end{lstlisting}
\end{center}
As mentioned in the issue tracker, the first step to implementing this feature will be adding the ability to use a wildcard operator. Once the wildcard operator is available, implementing XPath queries should only be a matter of converting the XPath query to a BSON document query and passing it along to the default querying mechanism. The specific files that I will likely be editing are btree.cpp (starting with line 482), pdfile.cpp (starting with line 620), and dbhelpers.cpp (starting with line 160).

\subsection{Expanding Geo-spatial Search}
MongoDB already has support for two-dimensional geo-spatial indexes.
These can be used to find the closest documents to any given location.
Additionally, one can query for all points inside a bounding shape. (currently
only a bounding rectangle and a bounding circle are supported). As JIRA ticket
SERVER-772\cite{18} indicates it would be very useful to have the ability to
query for points inside any polygon.

The geo-spatial API for MongoDB is very general, the existing ``\$box'' and ``\$circle''
are implemented as plugins on top of the API.
This work will most likely occur in the db/geo/2d.cpp module of the database. The new n-point polygon
search should be modeled after the existing ``box'' and ``circle'' searches. It should be as straight foreword
as adding a new polygon plugin class and registering it as a command to the database. Additional code will most
likely need to be written to support the polygon operations.
A number of unit tests will also need to be added to the jstests/geo folder to make sure the implementation is sound.

\subsection{User Authentication}
Currently MongoDB has no way to tell if a client is currently authenticated
to a MongoDB instance. This issue is outlined in JIRA ticket SERVER-1698\cite{19}.
We thought this issue would be a relatively simple thing to implement and would be
a good way to get started with working on the MongoDB database engine code.

The majority of the code will be added to the db/security\_commands.cpp module.
It should be a fairly straight foreword addition, a new database command will be
added which uses the existing isAuthorized method from the database AuthorizationInfo
class. The command will simply report the result of this command back to the user.
To go along with the database command, a accompanying mongo client command will be
added to the shell/db.js module. This will give the user a convenient way to query
if the client is authenticated to a database. The use will be able to call this
with a syntax similar to:
\begin{lstlisting}
  db.isAuthenticated()
\end{lstlisting}


\newpage

\section{Revisions}

\subsection{Expanding Geo Spatial Search}

Originally, our paper listed one of our desired features as implementing N-Dimensional
Geo-spatial Indexes to MongoDB.
\begin{quote}
However as the MongoDB JIRA ticket SERVER-691\cite{9} requests, the ability to
not just limit our selves to two dimensions and be able to support 3D or even N-Dimensional
queries would be a very interesting feature. The geo-spatial search could be used for
3D virtual world feature storage. Another potential use case would be the tracking of air planes
in the sky to make sure they are at least a $d$ distance away from one other.
This could be implemented using a four dimensional geo-spatial index where three of the dimensions
represent the point in 3D space, and the final dimension representing time. Using N-Dimensional
geo-spatial querying a user could query all four dimensions.
\end{quote}
As our team worked on our features it became apparent that the N-Dimensonal Geo
Spatial Search was far too ambitious of a project for our alloted time.
N-Dimensional data would require modifying the database to use KD-Trees,
R-trees, Quad-trees or other similar non B-tree based storage data structures.
Given the high coupling of the MongoDB code, this task in itself would take
at least a month to build and test correctly.
If we had tried to implement the actual query support, we would not have been able
to complete any of our deliverables on time.

Since the team was still interested in this area we decided to change the feature to
implementing N-point polygon searches using the existing 2D geo-spatial API.

\subsection{User Authentication}
This section was added since our initial submission, it was a very small simple feature to implement
and we thought it would be a good addition to the database. MongoDB can have some
odd rules about when a database has authentication turned on or not. Without
this feature there are times where you just don't know why the client isn't working.

\section{Addendums}

\subsection{Parallel Index Building}
We will not be using more threads than the size of the fan out of a B-tree node
since this will require multiple new levels in the final B-tree. Taking advantage of
the ability to have more threads than the number of keys in a node would require
a large number of cores on the system. Furthermore, it would be much more difficult
to implement.

\subsection{XPath}
It appears our goal to include support for XPath-like queries was somewhat
overzealous. The sheer multitude of query commands supported by XPath
exceeds our capabilities for the allotted time frame. Therefore, we will be
adding support for wild card queries and as many XPath features as we can
manage before the project due date. At a minimum, we expect to have support
for basic path expressions (using forward slashes instead of dot notation).
Time permitting, we will also include the ability to use predicates in the
path expression instead of as an argument for the query. For example, one
would be able to use the expression
\begin{lstlisting}

db.zoo.find({"/animal/panda[name='Burny']"})
\end{lstlisting}
instead of
\begin{lstlisting}

db.zoo.find({"/animal/panda/name':'Burny"})
\end{lstlisting}
to find a panda named Burny, or
\begin{lstlisting}

db.zoo.find({"/animal/monkey[3]"})
\end{lstlisting}
instead of
\begin{lstlisting}

db.zoo.find({
  "/animal/monkey":{$exists:true}
}).skip(2).limit(1)
\end{lstlisting}
to find the
third monkey in the database. As is apparent by the aforementioned
examples, adding the ability to include predicates in the path expression
would be extremely beneficial; it would make performing queries far more
intuitive.




\newpage
%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
\balancecolumns
% That's all folks!
\end{document}
